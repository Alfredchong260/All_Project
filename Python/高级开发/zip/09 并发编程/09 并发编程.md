# 多线程

## 线程

线程是一个单独的执行流程。这意味着您的程序将同时发生两件事。但是对于大多数 Python 3 实现，不同的线程实际上并不是同时执行的：它们只是看起来像。

很容易将线程视为在程序上运行两个（或更多）不同的处理器，每个处理器同时执行一项独立的任务。这几乎是正确的。线程可能在不同的处理器上运行，但它们一次只运行一个。

同时运行多个任务需要非标准的 Python 实现，用不同的语言编写一些代码，或者使用 `multiprocessing` 带来一些额外开销的代码。

由于 CPython 实现 Python 的工作方式，线程可能无法加速所有任务。这是因为与 GIL 的交互基本上限制了一次运行一个 Python 线程。

花费大量时间等待外部事件的任务通常是使用线程的良好选择。需要大量 CPU 计算并且花费很少时间等待外部事件的问题可能根本不会运行得更快。

这适用于用Python编写并在标准 CPython 实现上运行的代码。如果您的线程是用 C语言编写的，那么它们就能够释放GIL并同时运行。如果您正在运行不同的 Python 实现，请查看文档，了解它如何处理线程。

如果您正在运行标准的Python实现，只使用 Python 编写，并且遇到 CPU 限制问题，那么您应该检查`multiprocessing`模块。

构建程序以使用线程也可以提高程序的运行速度。您将在本教程中学习的大多数示例都不一定会运行得更快，因为它们使用线程。在其中使用线程有助于使设计更清晰，更容易推理。

![多线程—](assets/多线程—.png)



### 顺序执行逻辑

在默认的情况下，代码的执行逻辑是从上到下，从左到右。并且一次只能做一件事情，即使是阻塞操作，也会停止不动。

以烧水泡茶为例，它需要做 7 项工作，即洗壶，灌凉水，烧水，洗茶杯，放茶叶，冲开水泡茶。

要完成这几项工作，可以有以下几种程序：

  １.洗好开水壶，灌上凉水，放在火上，等待水开；水开后，再洗茶杯，准备茶叶，冲水泡茶。

  ２.先洗好水壶，洗好茶杯，放好茶叶，一切就绪，再放水烧水，水开后再冲水饮茶；

  ３.洗净开水壶，灌水烧水；烧水过程中，洗茶杯，放茶叶，水开后泡茶喝。

![image-20201211145511532](assets/image-20201211145511532.png)

**顺序执行逻辑** 

```python
import time

start_time = time.time()
print('1. 洗壶：1min')
time.sleep(1)
print('2. 灌凉水：1min')
time.sleep(1)
print('3. 烧水：1min')
time.sleep(1)
print('4. 等水烧开：3min')
time.sleep(1)
time.sleep(1)
time.sleep(1)
print('5. 洗茶杯：1min')
time.sleep(1)
print('6. 放茶叶：1min')
time.sleep(1)
print('7. 泡茶：1min')
time.sleep(1)
print('总运行时间', time.time() - start_time)

```

### 多线程异步执行

在默认的情况下，像等水烧开这种耗时的操作计算机也会在等着事情做完之后才会去做下一件事情，程序员可以指定给计算机安排任务。让计算机遇到耗时的事情之后，可以在等待的同时去做其他的事情。

```python
import time
import threading


def work():
    """只有函数对象才能使用多线程"""
    print('5. 洗茶杯：1min')
    time.sleep(1)
    print('6. 放茶叶：1min')
    time.sleep(1)


start_time = time.time()

print('1. 洗壶：1min')
time.sleep(1)
print('2. 灌凉水：1min')
time.sleep(1)
print('3. 烧水：1min')
time.sleep(1)
print('4. 等水烧开：3min')
work_thread = threading.Thread(target=work)
work_thread.start()
time.sleep(1)  # 5. 洗茶杯：1min
time.sleep(1)  # 6. 放茶叶：1min
time.sleep(1)
# 5 6 需要请一个帮手帮我们去做
# print('5. 洗茶杯：1min')
# time.sleep(1)
# print('6. 放茶叶：1min')
# time.sleep(1)
# 多线程必须要是一个函数对象

print('7. 泡茶：1min')
time.sleep(1)

print('总共花了：', time.time() - start_time)

```



## 创建线程

现在您已经了解了线程是什么，让我们学习如何创建一个线程。Python标准库提供 [`threading`](https://docs.python.org/3/library/threading.html) 。 `Thread` 在这个模块中，很好地封装了线程，提供了一个干净的界面来使用它们。

要启动一个单独的线程，您需要创建一个`Thread`实例，然后告诉它`.start()`：

```python
import time
import threading


def download():
    print("开始下载文件...")
    time.sleep(1)
    print("完成下载文件...")


def upload():
    print("开始上传文件...")
    time.sleep(1)
    print("完成上传文件...")


download()
upload()
```

注意

- 很显然刚刚的程序并没有完成上传和下载同时进行的要求
- 如果想要实现“上传与下载”同时进行，那么就需要一个新的方法，叫做：**多任务** 

### 使用 threading 模块

> python 的 thread 模块是底层的模块，python 的 threading 模块是对 thread 做了一些包装的，可以更加方便的被使用

当一个进程启动之后，会默认产生一个主线程，因为线程是程序执行流的最小单元，当设置多线程时，主线程会创建多个子线程，在python中，默认情况下（其实就是setDaemon(False)），主线程执行完自己的任务以后，就退出了，此时子线程会继续执行自己的任务，直到自己的任务结束。

```python
import time
import threading


def download():
    print("开始下载文件...")
    time.sleep(1)
    print("完成下载文件...")


def upload():
    print("开始上传文件...")
    time.sleep(1)
    print("完成上传文件...")




download_thread = threading.Thread(target=download)
download_thread.start()
upload_thread = threading.Thread(target=upload)
upload_thread.start()
```



### 守护线程

计算机科学中，守护线程（`daemon`） 是在后台运行的过程。

Python `threading` 具有更具体的含义 `daemon`。程序退出时 `daemon` 线程将立即关闭。考虑这些定义的一种方法是将 `daemon` 线程设置为在后台运行的线程，而不必担心将其关闭。

当我们使用 `setDaemon(True)` 方法，设置子线程为守护线程时，主线程一旦执行结束，则全部线程全部被终止执行，可能出现的情况就是，子线程的任务还没有完全执行结束，就被迫停止。

```python
# coding=utf-8
import threading
import time


def upload():
    print("开始上传文件...")
    time.sleep(1)
    print("完成上传文件...")


def download(num):
    print("开始下载文件...")
    time.sleep(1)
    print("完成下载文件...")


if __name__ == '__main__':
    num = 10
    thread1 = threading.Thread(target=upload)
    thread2 = threading.Thread(target=download)
    # 设置为守护线程 当主线程运行完时 子线程被 kill 掉
    thread1.setDaemon(True)
    thread2.setDaemon(True)
    thread1.start()
    thread2.start()

    
    # 默认情况下 主线程退出与时 子线程不会被 kill 掉
	print("主线程结束")

```



## 无锁不安全

先来看一个案例

```python
import threading

number = 0


def add_one():
    global number
    # 运行一百次加 1 运算
    for i in range(100):
        number += 1


if __name__ == '__main__':
    # 两个线程都进行加法运算
    for i in range(2):
        thread = threading.Thread(target=add_one)
        thread.start()
    
    # 当所有线程运行完毕之后
    while len(threading.enumerate()) > 1:
        pass
    
    print(number)

```

如果将 add_one 方法内的 100 改成 1000000 运行试试，为何得到的结果不是预料之中的结果？

### 线程能加速的原理

#### 单线程

在使用两个线程深入研究此问题之前，让我们回过头来讨论一下单线程如何工作的一些细节。

你不会深入了解这里的所有细节，因为这在这个级别并不重要。我们还将以一种技术上不准确的方式简化一些事情，但会让您对正在发生的事情有正确的认识。

当使用 `ThreadPoolExecutor` 运行每个线程时，我们使用 `executor.submit(database.update, index)` 指定运行的函数以及传递给它的参数。

结果是池中的每个线程都将调用 `database.update(index)` 。请注意，它`database`是对`FakeDatabase`创建的一个对象的引用`__main__`。调用`.update()`该对象会调用该对象上的[实例方法](https://realpython.com/instance-class-and-static-methods-demystified/)。

每个线程都将引用同一个 `FakeDatabase` 的实例对象 `database` 。每个线程也将具有唯一值。

![](assets/intro-threading-shared-database.267a5d8c6aa1.png)

当线程开始运行时 `.update()`，它有自己的函数本地数据版本。在这种情况下`.update()`，这是`local_copy`。这绝对是件好事。否则，运行相同功能的两个线程将始终相互混淆。这意味着对函数作用域（或本地）的所有变量都是 **线程安全的**。

现在，您可以开始了解如果您使用单个线程和单个调用运行上面的程序会发生什么`.update()`。

`.update()`如果只运行一个线程，下面的图像将逐步执行。该语句显示在左侧，后面是一个图表，显示了线程`local_value`和共享中的值`database.value`：

![](assets/intro-threading-single-thread.85204fa11210.png)



图表的布局使得从上到下移动时间会增加。它在`Thread 1`创建时开始，在终止时结束。

当 `Thread 1` 启动时，`FakeDatabase.value` 是零。方法中的第一行代码 `local_copy = self.value` 将值零复制到局部变量。接下来，它会 `local_copy` 使用 `local_copy += 1` 语句增加值。你可以看到 `.value` 在 `Thread 1` 越来越设置为1。

下一步调用 `time.sleep()`，使当前线程暂停并允许其他线程运行。由于此示例中只有一个线程，因此无效。

当 `Thread 1` 从醒来，并继续，它复制了新的价值 `local_copy` 来 `FakeDatabase.value` ，然后线程完成。您可以看到 `database.value` 设置为1。

到现在为止还挺好。你跑了 `.update()` 一次然后 `FakeDatabase.value` 增加到一次。

#### 两个线程

回到竞争状态，两个线程将同时运行但不会同时运行。他们每个都有自己的版本，`local_copy`并且每个都指向相同的版本`database`。正是这个共享`database`对象会导致问题。

该程序以`Thread 1`运行开始`.update()`：

![](assets/intro-threading-two-threads-part1.c1c0e65a8481.png)

当 `Thread 1` 启动 `time.sleep()` 时，它允许其他线程开始运行。这是事情变得有趣的地方。

`Thread 2` 启动并执行相同的操作。它也复制 `database.value` 到它的私有 `local_copy` ，这个共享`database.value` 还没有更新：

![](assets/intro-threading-two-threads-part2.df42d4fbfe21.png)



当`Thread 2`最终进入睡眠状态时，共享`database.value`在零时仍未修改，并且两个私有版本都`local_copy`具有值1。

`Thread 1`现在醒来并保存其版本`local_copy`然后终止，`Thread 2`最后运行机会。`Thread 2`不知道在睡觉时`Thread 1`跑步和更新`database.value`。它存储*的*版本`local_copy`为`database.value`，也将其设置为一个：

![](assets/intro-threading-two-threads-part3.18576920f88f.png)

这两个线程具有对单个共享对象的交叉访问权限，从而覆盖彼此的结果。当一个线程在另一个线程完成访问之前释放内存或关闭文件句柄时，可能会出现类似的竞争条件。



### 无锁不安全的原因

dis库是python(默认的 `CPython` )自带的一个库,可以用来分析字节码

如果多个线程同时对同一个变量操作，会出现资源竞争问题，从而数据结果会不正确



在考虑竞争条件时，要记住两件事：

1. 即使是像操作一样的操作也 `x += 1` 需要多处理器。这些步骤中的每一步都是对处理器的单独指令。
2. 操作系统可以换哪个线程运行 *在任何时间* 。在任何这些小指令之后，可以换出一个线程。这意味着，一个线程可以被置于睡眠状态，让在另一个线程运行*中*一个Python语句。

让我们详细看看下面这个函数，它接受一个参数并递增它：

```python
# 没有锁
def add1(a):
    a += 1

"""add
1. load a  a = 0
2. load 1  1
3. +    1
4. 赋值给a a=1
"""

import dis
dis.dis(add1)
```

运行结果

```
 37           0 LOAD_FAST                0 (a)
              2 LOAD_CONST               1 (1)
              4 INPLACE_ADD
              6 STORE_FAST               0 (a)
              8 LOAD_CONST               0 (None)
             10 RETURN_VALUE
```

程序执行的过程

1. 执行`LOAD_FAST`数据值`x`

2. 执行a `LOAD_CONST 1`

3. 将`INPLACE_ADD`这些值添加到一起。

我们因特定原因停在这里。这是强制线程切换的`.update()`上述要点`time.sleep()`。完全有可能的是，每隔一段时间，操作系统就会在该确切点切换线程，即使没有`sleep()`，但是`sleep()`每次调用都会使它发生。



## 锁与死锁

### 互斥锁 LOCK

有许多方法可以避免或解决竞争条件。你不会在这里看到所有这些，但有一些经常使用。让我们开始学习 `Lock`。

要解决上面的竞争条件，您需要找到一种方法，一次只允许一个线程进入代码的读 - 修改 - 写部分。最常见的方法是`Lock`在Python中调用。

 `Lock` 是一个像通行证一样的物体。一次只能有一个线程 `Lock`。任何其他想要通过 `Lock` 的线程，必须等到`Lock` 的所有者释放它。

执行此操作的基本功能是`.acquire()`和`.release()`。如果锁已经被保持，则调用线程将一直等到它被释放。这里有一个重点。如果一个线程获得锁定但从未将其返回，则程序将被卡住。就会造成死锁。

幸运的是，Python `Lock`也将作为上下文管理器运行，因此您可以在`with`语句中使用它，并且当`with`块因任何原因退出时它会自动释放。

让我们来看看 `Lock` 。调用函数保持不变：

```python
...

def add_one():
    global number
    # 运行一百次加 1 运算
    for i in range(1000000):
        lock.acquire()
        number += 1
        lock.release()
...

```

`._lock` 在解锁状态下初始化，并由 `with` 语句锁定和释放。

值得注意的是，运行此函数的线程将保持该`Lock`状态，直到完全更新数据库为止。在这种情况下，这意味着它将保留`Lock`复制，更新，休眠，然后将值写回数据库。



![clip_image001](assets/clip_image001_thumb2.gif)

threading模块中定义了Lock类，可以方便的处理锁定：

```python
# 创建锁
lock = threading.Lock()

# 锁定
lock.acquire()

# 释放
lock.release()

```

**注意：** 

- 如果这个锁之前是没有上锁的，那么acquire不会堵塞
- 如果在调用acquire对这个锁上锁之前 它已经被 其他线程上了锁，那么此时acquire会堵塞，直到这个锁被解锁为止

### 死锁

在继续之前，您应该在使用时查看常见问题`Locks`。如您所见，如果`Lock`已经获取，则第二次调用`.acquire()`将等待持有`Lock`调用的线程`.release()`。运行此代码时，您认为会发生什么：

```python
import threading

l = threading.Lock()
print("第一次获取锁")
l.acquire()
print("第二次获取锁")
l.acquire()

```

当程序`l.acquire()`第二次调用时，它会挂起等待`Lock`释放。在此示例中，您可以通过删除第二个调用来修复死锁，但死锁通常发生在两个微妙的事情之一：

1.  `Lock`未正确发布的实现错误
2.  一个设计问题，其中实用程序函数需要由可能已经或可能没有的函数调用 `Lock`

第一种情况有时会发生，但使用`Lock`上下文管理器会大大减少频率。建议尽可能编写代码以使用上下文管理器，因为它们有助于避免异常跳过`.release()`调用的情况。

在某些语言中，设计问题可能有点棘手。值得庆幸的是，Python线程有一个名为的第二个对象，`RLock`专门针对这种情况而设计。它允许一个线程`.acquire()`的`RLock`多次调用之前`.release()`。该线程仍然需要调用`.release()`它调用的相同次数`.acquire()`，但无论如何它应该这样做。

`Lock`并且`RLock`是用于线程编程以防止竞争条件的两个基本工具。还有一些其他方式以不同的方式工作。在你看之前，让我们转向一个稍微不同的问题域。

此时已经进入到了死锁状态

### 总结

锁的好处：

- 确保了某段关键代码只能由一个线程从头到尾完整地执行

锁的坏处：

- 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了
- 由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁

## 队列（Queue）

- Queue 叫队列，是数据结构中的一种，基本上所有成熟的编程语言都内置了对 Queue 的支持。
- Python 中的 Queue 模块实现了多生产者和多消费者模型，当需要在多线程编程中非常实用。而且该模块中的 Queue 类实现了锁原语，不需要再考虑多线程安全问题
- 该模块内置了三种类型的 Queue，分别是 `class queue.Queue(maxsize=0)`，`class queue.LifoQueue(maxsize=0)` 和 `class queue.PriorityQueue(maxsize=0)`。它们三个的区别仅仅是取出时的顺序不一致而已。

### 常用操作

```
class queue.Queue(maxsize=0)

```

上面所说的内置队列，其中 maxsize 是个整数，用于设置可以放入队列中的任务数的上限。当达到这个大小的时候，插入操作将阻塞至队列中的任务被消费掉。如果 maxsize 小于等于零，则队列尺寸为无限大。

**添加任务**

向队列中添加任务，直接调用 `put()` 函数即可

```
import queue
>>> q = queue.Queue(maxsize=1)
>>> q.put(100)

```

- `put()` 函数完整的函数签名如下 `Queue.put(item, block=True, timeout=None)`，如你所见，该函数有两个可选参数。
- 默认情况下，在队列满时，该函数会一直阻塞，直到队列中有空余的位置可以添加任务为止。如果 timeout 是正数，则最多阻塞 timeout 秒，如果这段时间内还没有空余的位置出来，则会引发 `Full` 异常。
- 当 block 为 false 时，timeout 参数将失效。同时如果队列中没有空余的位置可添加任务则会引发 `Full` 异常，否则会直接把任务放入队列并返回，不会阻塞。
- 另外，还可以通过 `Queue.put_nowait(item)` 来添加任务，相当于 `Queue.put(item, False)`，不再赘述。同样，在队列满时，该操作会引发 `Full` 异常。

**获取任务**

```
>>> import queue
>>> q = queue.Queue()
>>> q.put(100)
>>> q.get()
100

```

- 与 `put()` 函数一样，`get()` 函数也有两个可选参数，完整签名如下 `Queue.get(block=True, timeout=None)`。
- 默认情况下，当队列空时调用该函数会一直阻塞，直到队列中有任务可获取为止。如果 timeout 是正数，则最多阻塞 timeout 秒，如果这段时间内还没有任务可获取，则会引发`Empty` 异常。

- 当 block 为 false 时，timeout 参数将失效。同时如果队列中没有任务可获取则会立刻引发 `Empty` 异常，否则会直接获取一个任务并返回，不会阻塞。
- 另外，还可以通过 `Queue.get_nowait()` 来获取任务，相当于 `Queue.get(False)`，不再赘述。同样，在队列为空时，该操作会引发 `Empty` 异常。

#### 其他常用操作

+ 获取队列大小

  ```
  >>> import queue
  >>> q = queue.Queue()
  >>> q.put(100)
  >>> q.put(200)
  >>> q.qsize()
  2
  
  ```

+ 判断队列是否为空

  如果队列为空，返回 `True` ，否则返回 `False` 。如果 empty() 返回 `True` ，不保证后续调用的 put() 不被阻塞。类似的，如果 empty() 返回 `False` ，也不保证后续调用的 get() 不被阻塞。

+ 判断队列是否满

  如果队列是满的返回 `True` ，否则返回 `False` 。如果 full() 返回 `True` 不保证后续调用的 get() 不被阻塞。类似的，如果 full() 返回 `False` 也不保证后续调用的 put() 不被阻塞。

  ```
  >>> import queue
  >>> q = queue.Queue(maxsize=1)
  >>> q.empty()
  True
  >>> q.full()
  False
  >>> q.put(100)
  >>> q.empty()
  False
  >>> q.full()
  True
  
  ```

  



## 生产者-消费者模型

在[生产者-消费者问题](https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem)是用来看看线程或进程同步的问题一个标准的计算机科学问题。您将看一下它的变体，以了解Python `threading`模块提供的原语。

比如一个包子铺中的顾客吃包子，和厨师做包子，不可能是将包子一块做出来，在给顾客吃,但是单线程只能这么做

多线程来执行，厨师一边做包子，顾客一边吃包子，当顾客少时，厨师做的包子就放在一个容器中，等着顾客来吃，当顾客多的时候，就从容器中先取出来给顾客吃，厨师继续做包子用队列来模拟这个容器

如果希望一次能够在管道中处理多个值，那么您将需要一个管道数据结构，允许数字随着数据的备份而增长和缩小 `producer` 。

Python的标准库有一个`queue`模块，而该模块又有一个`Queue`类。让我们改变`Pipeline`使用a `Queue`而不仅仅是受a保护的变量`Lock`。您也可以通过不同的方式使用不同的原始用Python停止工作线程`threading`，一个`Event`。

让我们从开始吧`Event`。该`threading.Event`对象允许一个线程发出信号`event`，许多其他线程可以等待它`event`发生。这段代码中的关键用法是等待事件的线程不一定需要停止它们正在做的事情，它们只能`Event`偶尔检查一次的状态。

触发事件可以是很多事情。在这个例子中，主线程将只是休眠一段时间然后 `.set()` 它

这里唯一的变化是创建 `event` 第6行对象，传递 `event` 作为线8,9的参数，并且在线路11至13的最后一节，其睡眠用于第二，日志消息，然后调用 `.set()` 对事件。

`producer`生成者：

```python
def producer(pipeline):
    """生产者 厨师做包子"""
    for index in range(1, 100000):
        time.sleep(0.1 
        print("做出一个包子: %s" % index)
        # 将包子放到蒸笼里面
        pipeline.put(f'第{index}个包子')

```

它现在将循环，直到它看到事件在第3行设置。它也不再将`SENTINEL`值放入`pipeline`。

`consumer` 不得不改变一点：

```python
def consumer(pipeline):
    """消费者 客户吃包子"""
    while True:
        message = pipeline.get()
        print(message)
        print(f'消费者吃了{message}')

```

在消费者完成之前确保队列为空可防止另一个有趣的问题。如果`consumer`确实在其中`pipeline`包含消息时退出，则可能发生两件坏事。首先是你丢失了那些最终的消息，但更严重的是，`producer`可以抓住尝试将消息添加到完整队列并且永远不会返回。

`Queue`初始化时有一个可选参数，用于指定队列的最大大小。

如果给出一个正数`maxsize`，它会将队列限制为该元素数，导致`.put()`阻塞直到少于`maxsize`元素。如果未指定`maxsize`，则队列将增长到计算机内存的限制。

`.get_message()`并且`.set_message()`变小了。他们基本上包裹`.get()`和`.put()`上`Queue`。您可能想知道阻止线程引起竞争条件的所有锁定代码的位置。

编写标准库的核心开发人员知道a `Queue`经常在多线程环境中使用，并将所有锁定代码合并到`Queue`自身内部。`Queue`是线程安全的。

以下是代码`queue.Queue`直接使用的内容：

```python
import queue
import random
import threading
import concurrent.futures
import time


def producer(pipeline):
    """生产者 厨师做包子"""
    for index in range(1, 100000):
        time.sleep(0.1)
        print("做出一个包子: %s" % index)
        # 将包子放到蒸笼里面
        pipeline.put(f'第{index}个包子')


def consumer(pipeline):
    """消费者 客户吃包子"""
    while True:
        message = pipeline.get()
        print(message)
        print(f'消费者吃了{message}')


if __name__ == "__main__":
    pipeline = queue.Queue(maxsize=10)
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        executor.submit(producer, pipeline)
        executor.submit(consumer, pipeline)

        time.sleep(0.1)


```

这更容易阅读，并展示了如何使用Python的内置基元来简化复杂问题。

`Lock`并且`Queue`是解决并发问题的方便类，但标准库还提供了其他类。在结束本教程之前，让我们快速调查一下这些教程。

# 多进程

## GIL

在非 python 环境中，单核情况下，同时只能有一个任务执行。多核时可以支持多个线程同时执行。但是在python中，无论有多少核，同时只能执行一个线程。究其原因，这就是由于GIL的存在导致的。

GIL的全称是 Global Interpreter Lock (全局解释器锁)，来源是python设计之初的考虑，为了数据安全所做的决定。某个线程想要执行，必须先拿到GIL，我们可以把 GIL 看作是“通行证”，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。GIL只在cpython中才有，因为cpython调用的是c语言的原生线程，所以他不能直接操作cpu，只能利用GIL保证同一时间只能有一个线程拿到数据。而在pypy和jpython中是没有GIL的。



**Python多线程的工作过程：** 
python在使用多线程的时候，调用的是c语言的原生线程。

1. 拿到公共数据
2. 申请 gil 
3. python 解释器调用 os 原生线程
4. os 操作 cpu 执行运算
5. 当该线程执行时间到后，无论运算是否已经执行完，gil 都被要求释放
6. 进而由其他进程重复上面的过程
7. 等其他进程执行完后，又会切换到之前的线程（从他记录的上下文继续执行）
   整个过程是每个线程执行自己的运算，当执行时间到就进行切换（context switch）。



**python针对不同类型的代码执行效率也是不同的：**

1、CPU密集型代码(各种循环处理、计算等等)，在这种情况下，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对CPU密集型代码并不友好。
2、IO密集型代码(文件处理、网络爬虫等涉及文件读写的操作)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好。



**使用建议？**

python下想要充分利用多核CPU，就用多进程。因为每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。



**GIL在python中的版本差异：**

1、在python2.x里，GIL的释放逻辑是当前线程遇见`IO操作`或者`ticks计数达到100`时进行释放。（ticks可以看作是python自身的一个计数器，专门做用于GIL，每次释放后归零，这个计数可以通过sys.setcheckinterval 来调整）。而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源。并且由于GIL锁存在，python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，这就是为什么在多核CPU上，python的多线程效率并不高。
2、在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。

## 进程以及状态

一个程序的执行实例就是一个 **进程** 。每一个进程提供执行程序所需的所有资源。（进程本质上是资源的集合）

一个进程有一个虚拟的地址空间、可执行的代码、操作系统的接口、安全的上下文（记录启动该进程的用户和权限等等）、唯一的进程ID、环境变量、优先级类、最小和最大的工作空间（内存空间），还要有至少一个线程。

每一个进程启动时都会最先产生一个线程，即主线程。然后主线程会再创建其他的子线程。

**进程的状态** 

工作中，任务数往往大于 `cpu` 的核数，即一定有一些任务正在执行，而另外一些任务在等待 `cpu` 进行执行，因此导致了有了不同的状态

![assets](assets/Snip20160830_3.png)

- 就绪态：运行的条件都已经满去，正在等在cpu执行
- 执行态：cpu正在执行其功能
- 等待态：等待某些条件满足，例如一个程序sleep了，此时就处于等待态

而网络IO主要延时由： 服务器响应延时 + 带宽限制 + 网络延时 + 跳转路由延时 + 本地接收延时决定。（一般为几十到几千毫秒，受环境干扰极大）

![assets](assets/v2-0bca913bed8f7d40ac523dbb7688da07_hd.jpg)

原文地址：[点击这里](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter4/02_Using_the_concurrent.futures_Python_modules.html) 

## 进程的创建

> multiprocessing

multiprocessing 是 Python 的标准模块，它既可以用来编写多进程，也可以用来编写多线程。multiprocessing  提供了一个Process类来代表一个进程对象，这个对象可以理解为是一个独立的进程，可以执行另外的事情

### 用进程实现同时上传与下载文件

```python
# -*- coding: utf-8 -*-
import multiprocessing
import time


def upload():
    print("开始上传文件...")
    time.sleep(1)
    print("完成上传文件...")


def download():
    print("开始下载文件...")
    time.sleep(1)
    print("完成下载文件...")


def main():
    multiprocessing.Process(target=upload).start()
    multiprocessing.Process(target=download).start()


if __name__ == '__main__':
    main()


```

说明：

创建子进程时，只需要传入一个执行函数和函数的参数，创建一个 Process 实例，用 start() 方法启动

### Process

**Process 介绍：** 

构造方法：

- Process([group [, target [, name [, args [, kwargs]]]]])
- group: 线程组，目前还没有实现，库引用中提示必须是 None；
- target: 要执行的方法；
- name: 进程名；
- args/kwargs: 要传入方法的参数。

实例方法：

- is_alive()：返回进程是否在运行。
- join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的 timeout（可选参数）。
- start()：进程准备就绪，等待 CPU 调度。
- run()：strat() 调用 run 方法，如果实例进程时未制定传入 target，start 执行默认 run() 方法。
- terminate()：不管任务是否完成，立即停止工作进程。

属性：

- authkey
- daemon：和线程的 setDeamon 功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。
- exitcode(进程在运行时为 None、如果为 –N，表示被信号 N 结束）。
- name：进程名字。
- pid：进程号。



### 给子进程指定的函数传递参数

```python
# -*- coding: utf-8 -*-
import multiprocessing


# 多进程多进程传参
def run_process(n, a, name, age):

    print(n, a, name, age)


if __name__ == '__main__':
    # 可以利用换行是代码看起来更简洁
    multiprocessing.Process(target=run_process,
                            args=(18, 1),
                            kwargs={'name': '张三', 'age': 18}).start()

```



### 进程间不同享全局变量

因为属于不同的进程，进程与进程之间的变量不共享

```python
# -*- coding: utf-8 -*-
import multiprocessing
import threading

# 主进程
l = [1, 2, 3, 4, 5]


def list_append(p):
    print(l.pop())
    print(l.pop())
    print(l.pop())
    print('进程{}修改的内容'.format(p), l)


def list_append2(p):
    print(l.pop())
    print(l.pop())
    print('进程{}修改的内容'.format(p), l)


if __name__ == '__main__':
    # t1 = threading.Thread(target=list_append, args=('p1',))
    # t1.start()
    # t2 = threading.Thread(target=list_append2, args=('p2',))
    # t2.start()
    p2 = multiprocessing.Process(target=list_append2, args=('p2',))
    p2.start()
    p1 = multiprocessing.Process(target=list_append, args=('p1',))
    p1.start()


```

### Queue的使用

Process 之间有时需要通信，操作系统提供了很多机制来实现进程间的通信。

可以使用 multiprocessing 模块的 Queue 实现多进程之间的数据传递，Queue 本身是一个消息列队程序，首先用一个小实例来演示一下 Queue 的工作原理：

```python
# coding=utf-8
from multiprocessing import Queue

q = Queue(3)  # 初始化一个Queue对象，最多可接收三条put消息
q.put("消息1")
q.put("消息2")
q.put("消息3")

# 因为消息列队已满下面的try都会抛出异常，第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常
try:
    q.put("消息4", True, 2)
except:
    print("消息列队已满，现有消息数量:%s" % q.qsize())

try:
    q.put_nowait("消息4")
except:
    print("消息列队已满，现有消息数量:%s" % q.qsize())

# 推荐的方式，先判断消息列队是否已满，再写入
if not q.full():
    q.put_nowait("消息4")

# 读取消息时，先判断消息列队是否为空，再读取
if not q.empty():
    for i in range(q.qsize()):
        print(q.get_nowait())

```

运行结果:

```python
消息列队已满，现有消息数量:3

消息列队已满，现有消息数量:3
消息1
消息2
消息3

```

**说明** 

初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）；

- Queue.qsize()：返回当前队列包含的消息数量；
- Queue.empty()：如果队列为空，返回True，反之False ；
- Queue.full()：如果队列满了，返回True,反之False；
- Queue.get([block[, timeout]])：获取队列中的一条消息，然后将其从列队中移除，block默认值为True；
  - 如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出"Queue.Empty"异常；
  - 如果block值为False，消息列队如果为空，则会立刻抛出"Queue.Empty"异常；
- Queue.get_nowait()：相当Queue.get(False)；
- Queue.put(item,[block[, timeout]])：将item消息写入队列，block默认值为True；
  - 如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出"Queue.Full"异常；
  - 如果block值为False，消息列队如果没有空间可写入，则会立刻抛出"Queue.Full"异常；
- Queue.put_nowait(item)：相当Queue.put(item, False)；





## 并发速度对比

单线程、多线程、多进程效果对比

### IO密集型对比

```python
# -*- coding: utf-8 -*-
import concurrent.futures
import time
import random

urls = [
    f'https://maoyan.com/board/4?offset={page}' for page in range(1000)
]


def download(url):
    # print(url)
    # 延时从操作
    time.sleep(0.0000001)


if __name__ == '__main__':
    """单线程"""
    start_time = time.time()
    for url in urls:
        download(url)
    print("单线程执行：" + str(time.time() - start_time), "秒")

    """多线程"""
    start_time_1 = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        for url in urls:
            executor.submit(download, url)
    print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")

    """多进程"""
    start_time_1 = time.time()
    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:
        for url in urls:
            executor.submit(download, url)
    print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")


```

运行这个代码，我们可以看到运行时间的输出：

```
单线程执行：1.064488172531128 秒
线程池计算的时间：0.4077413082122803 秒
线程池计算的时间：0.46396422386169434 秒

```

### CPU密集型

```python
# -*- coding: utf-8 -*-
import concurrent.futures
import time

number_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]


def evaluate_item(x):
    """计算总和，这里只是为了消耗时间"""
    a = 0
    for i in range(0, 100):
        # 重复计算 消耗时间 cpu计算能力
        a = a + i
        time.sleep(0.00000001)
    return x


if __name__ == '__main__':
    """单线程"""
    start_time = time.time()
    for item in number_list:
        evaluate_item(item)
    print("单线程执行：" + str(time.time() - start_time), "秒")

    """多线程"""
    start_time_1 = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        for item in number_list:
            executor.submit(evaluate_item, item)
    print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")

    """多进程"""
    start_time_2 = time.time()
    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:
        for item in number_list:
            executor.submit(evaluate_item, item)
    print("进程池计算的时间：" + str(time.time() - start_time_2), "秒")


```



## 进程、线程对比

- 进程，能够完成多任务，比如 在一台电脑上能够同时运行多个QQ
- 线程，能够完成多任务，比如 一个QQ中的多个聊天窗口



进程是系统进行资源分配和调度的一个独立单位.

线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.



区别

- 一个程序至少有一个进程,一个进程至少有一个线程.

- 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。

- 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率

  ![assets](assets/QQ20170731-192951@2x.png)

- 线程不能够独立执行，必须依存在进程中

**优缺点** 

线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。

关于多进程和多线程，教科书上最经典的一句话是“进程是资源分配的最小单位，线程是CPU调度的最小单位”。这句话应付考试基本上够了，但如果在工作中遇到类似的选择问题，那就没有那么简单了，选的不好，会让你深受其害。所以他也是面试者最喜欢考察的题目之一。

我们按照多个不同的维度，来看看多进程和多线程的对比（注：都是相对的，不是说一个好得不得了，另一个差的无法忍受）

| 维度           | 多进程                                                       | 多线程                                 | 总结     |
| -------------- | ------------------------------------------------------------ | -------------------------------------- | -------- |
| 数据共享、同步 | 数据是分开的:共享复杂，需要用IPC;同步简单                    | 多线程共享进程数据：共享简单；同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU利用率低                            | 占用内存少，切换简单，CPU利用率高      | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度快             | 线程占优 |
| 编程调试       | 编程简单，调试简单                                           | 编程复杂，调试复杂                     | 进程占优 |
| 可靠性         | 进程间不会相互影响                                           | 一个线程挂掉将导致整个进程挂掉         | 进程占优 |
| 分布式         | 适应于多核、多机分布 ；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布                         | 进程占优 |

然后我们来看下线程和进程间的比较

|          | 多进程                                                       | 多线程                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 优点     | 内存隔离，单进程已成不会导致整个应用崩溃。方便调试           | 提高系统的并发性，并且开销小                                 |
| 缺点     | 进程间调用，通讯和切换开销均比多线程大                       | 没有内存隔离，单线程的崩溃会导致整个应用的推出，发生内存bug时，定位及其不方便（回调噩梦） |
| 使用场景 | 目标子功能交互少，如果资源和性能许可，请设计由多个子应用程序来组合完成。 | 存在大量IO、网络等耗时操作，或需要与用户交互时，使用多线程有利于提高系统的并行性和用户界面交互的体验。 |



1) 需要频繁创建销毁的优先用线程。
   实例：web服务器。来一个建立一个线程，断了就销毁线程。要是用进程，创建和销毁的代价是很难承受的。

2. 需要进行大量计算的优先使用进程。
   所谓大量计算，当然就是要消耗很多cpu，切换频繁了，这种情况先线程是最合适的。
   实例：图像处理、算法处理

3. 强相关的处理用线程，若相关的处理用进程。
   什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。
   一般的server需要完成如下任务：消息收发和消息处理。消息收发和消息处理就是弱相关的任务，而消息处理里面可能又分为消息解码、业务处理，这两个任务相对来说相关性就要强多了。因此消息收发和消息处理可以分进程设计，消息解码和业务处理可以分线程设计。
4. 可能扩展到多机分布的用进程，多核分布的用线程。
5. 都满足需求的情况下，用你最熟悉、最拿手的方式。

 

至于”数据共享、同步“、“编程、调试”、“可靠性”这几个维度的所谓的“复杂、简单”应该怎么取舍，只能说：没有明确的选择方法。一般有一个选择原则：如果多进程和多线程都能够满足要求，那么选择你最熟悉、最拿手的那个。

买了一台服务器  2核4线程 部署一个博客项目 2G内存

python开发的应用 一个进程一个线程 同一时刻只能处理一个请求 并发数只有1



并发    项目部署启动 6（2进程*（1+2线程）） 并发数就是6 线程开的越多 会消耗内存

线程并发有先后顺序，并行同时去做

并行数 最大是 2 

并行 同时做多件事情 一起做

### 关系对比

+ 线程是依附在进程里面的，没有进程就没有线程。
+ 一个进程默认提供一条线程，进程可以创建多个线程。

![image-20200710161900848](assets/image-20200710161900848.png)

### 优缺点对比

进程优缺点:

+ 优点：可以用多核
+ 缺点：资源开销大

线程优缺点:

+ 优点：资源开销小
+ 缺点：不能使用多核

### 要点总结

1. 进程和线程都是完成多任务的一种方式

2. 多进程要比多线程消耗的资源多，但是多进程开发比单进程多线程开发稳定性要强，某个进程挂掉不会影响其它进程。

3. 多进程可以使用cpu的多核运行，多线程可以共享全局变量。

4. 线程不能单独执行必须依附在进程里面



## 概念问题（面试常问）

以下是和并发相关的两个术语。

- 同步
  一件事接着一件事发生，就像送葬队伍一样。 
- 异步
  任务是互相独立的，就像派对参与者从不同的车上下来一样



在计算机中，如果你的程序在等待，通常是因为以下两个原因。

- I/O 限制
  这个限制很常见。计算机的 CPU 速度非常快——比计算机内存快几百倍，比硬盘或者
  网络快几千倍。
- CPU 限制
  在处理数字运算任务时，比如科学计算或者图形计算，很容易遇到这个限制。



 并发（concurrency）和并行（parallellism）是

+ 并发

  一件事情由多个人同时去做（多线程）

+ 并行

  多个人同时做多件事情（多进程）





## 附录：并发池

Python3.2 带来了 `concurrent.futures` 模块，这个模块具有线程池和进程池、管理并行编程任务、处理非确定性的执行流程、进程/线程同步等功能。

此模块由以下部分组成：

- `concurrent.futures.Executor`: 这是一个虚拟基类，提供了异步执行的方法。
- `submit(function, argument)`: 调度函数（可调用的对象）的执行，将 `argument` 作为参数传入。
- `map(function, argument)`: 将 `argument` 作为参数执行函数，以 **异步** 的方式。
- `shutdown(Wait=True)`: 发出让执行者释放所有资源的信号。
- `concurrent.futures.Future`: 其中包括函数的异步执行。Future对象是submit任务（即带有参数的functions）到executor的实例。

Executor是抽象类，可以通过子类访问，即线程或进程的 `ExecutorPools` 。因为，线程或进程的实例是依赖于资源的任务，所以最好以“池”的形式将他们组织在一起，作为可以重用的launcher或executor。

### 线程池

线程池或进程池是用于在程序中优化和简化线程/进程的使用。通过池，你可以提交任务给executor。池由两部分组成，一部分是内部的队列，存放着待执行的任务；另一部分是一系列的进程或线程，用于执行这些任务。池的概念主要目的是为了重用：让线程或进程在生命周期内可以多次使用。它减少了创建创建线程和进程的开销，提高了程序性能。重用不是必须的规则，但它是程序员在应用中使用池的主要原因。

#### 准备工作

`current.Futures` 模块提供了两种 `Executor` 的子类，各自独立操作一个线程池和一个进程池。这两个子类分别是：

- `concurrent.futures.ThreadPoolExecutor(max_workers)`
- `concurrent.futures.ProcessPoolExecutor(max_workers)`
- `max_workers` 参数表示最多有多少个worker并行执行任务。

下面的示例代码展示了线程池和进程池的功能。这里的任务是，给一个list `number_list` ，包含1到10。对list中的每一个数字，乘以1+2+3…+10000000的和（这个任务只是为了消耗时间）。

下面的代码分别测试了：

- 顺序执行
- 通过有5个worker的线程池执行
- 通过有5个worker的进程池执行

#### 顺序执行

我们创建了一个 urls 存放100000个待请求的网址，然后使用线程池去请求:

```python
import concurrent.futures
import time

urls = [
    f'https://maoyan.com/board/4?offset={page}' for page in range(100000)
]


def download(url):
    print(url)
    # 延时从操作
    time.sleep(1)

```

在主要程序中，我们先使用顺序执行跑了一次程序：:

```python
if __name__ == "__main__":
    # 顺序执行
    start_time = time.time()
    for item in number_list:
        evaluate_item(item)
    print("计算机顺序执行：" + str(time.time() - start_time), "秒")

```

#### 线程池运行

然后，我们使用了 `futures.ThreadPoolExecutor` 模块的线程池跑了一次：:

```python
if __name__ == "__main__":
    start_time_1 = time.time()
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        for url in urls:
            executor.submit(download, url)
    print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")

    # executor1 = concurrent.futures.ThreadPoolExecutor(max_workers=5)
    # for url in urls:
    #     executor.submit(download, url)
    # executor1.shutdown()
    # print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")

```

`ThreadPoolExecutor` 使用线程池中的一个线程执行给定的任务。池中一共有5个线程，每一个线程从池中取得一个任务然后执行它。当任务执行完成，再从池中拿到另一个任务。

当所有的任务执行完成后，打印出执行用的时间：:

```python
print("线程池计算的时间：" + str(time.time() - start_time_1), "秒")

```

### 进程池

```python
if __name__ == "__main__":
	start_time_2 = time.time()
    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:
        for url in urls:
            executor.submit(download, url)
    print("进程池计算的时间：" + str(time.time() - start_time_2), "秒")

    # executor2 = concurrent.futures.ProcessPoolExecutor(max_workers=5)
    # for url in urls:
    #     executor.submit(download, url)
    # executor2.shutdown()
    # print("进程池计算的时间：" + str(time.time() - start_time_2), "秒")

```

如同 `ThreadPoolExecutor` 一样， `ProcessPoolExecutor` 是一个executor，使用一个线程池来并行执行任务。然而，和 `ThreadPoolExecutor` 不同的是， `ProcessPoolExecutor` 使用了多核处理的模块，让我们可以不受GIL的限制，大大缩短执行时间。