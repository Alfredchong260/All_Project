


模块:
    1.找数据对应的url地址
    2.数据请求(requests, urllib)
    3.数据解析(parsel<xpath css re>)  lxml  bs4
    4.数据保存(json csv openpyxl)

    模块往往只能解决一个功能需求
    冗余操作(数据类型的转换, 参数)

框架:
    是整套需求的解决方案: 有底层运行逻辑

    只需要写爬虫的业务逻辑

    需要学习框架的特定语法, 特定功能

scrapy爬虫框架: pyspider
    分布式爬虫系统
